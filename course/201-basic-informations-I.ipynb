{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic informations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partitions\n",
    "\n",
    "Partition is a collection of divided data from a large dataset that is stored across the cluster.\n",
    "\n",
    "If there is only one executor the parallelism is one even if the parameter ```minPartitions > 1```. And if you have ```minPartitions = 1``` and more than one executor, the parallelism is only one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "# create a spark context\n",
    "sc = SparkContext(\"local\", \"Basic informations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile(\"sample_data/201-basic-informations.txt\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```.getNumPartitions()``` return the number of partitions in RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count\n",
    "\n",
    "```.count()``` - return the number of elements in this RDD.\n",
    "\n",
    "```.countByKey``` - count RDD elements by each key.\n",
    "\n",
    "```.countByValue``` - count RDD elements by value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'From fairest creatures we desire increase,': 4,\n",
       "             \"That thereby beauty's rose might never die,\": 2,\n",
       "             'But as the riper should by time decease,': 2,\n",
       "             'His tender heir might bear his memory:': 2,\n",
       "             'But thou contracted to thine own bright eyes,': 2,\n",
       "             \"Feed'st thy light's flame with self-substantial fuel,\": 1,\n",
       "             'Making a famine where abundance lies,': 1,\n",
       "             'Thy self thy foe, to thy sweet self too cruel:': 1,\n",
       "             \"Thou that art now the world's fresh ornament,\": 1,\n",
       "             'And only herald to the gaudy spring,': 1,\n",
       "             'Within thine own bud buriest thy content,': 1,\n",
       "             \"And tender churl mak'st waste in niggarding:\": 1,\n",
       "             'Pity the world, or else this glutton be,': 1,\n",
       "             \"To eat the world's due, by the grave and thee.\": 1,\n",
       "             'When forty winters shall besiege thy brow,': 1,\n",
       "             \"And dig deep trenches in thy beauty's field,\": 1,\n",
       "             \"Thy youth's proud livery so gazed on now,\": 1,\n",
       "             'Will be a tattered weed of small worth held:': 1,\n",
       "             'Then being asked, where all thy beauty lies,': 1,\n",
       "             'Where all the treasure of thy lusty days;': 1,\n",
       "             'To say within thine own deep sunken eyes,': 2,\n",
       "             'Were an all-eating shame, and thriftless praise.': 3,\n",
       "             \"How much more praise deserved thy beauty's use,\": 1,\n",
       "             \"If thou couldst answer 'This fair child of mine\": 1,\n",
       "             \"Shall sum my count, and make my old excuse'\": 1,\n",
       "             'Proving his beauty by succession thine.': 1,\n",
       "             'This were to be new made when thou art old,': 1,\n",
       "             \"And see thy blood warm when thou feel'st it cold.\": 1,\n",
       "             'Look in thy glass and tell the face thou viewest,': 1,\n",
       "             'Now is the time that face should form another,': 1,\n",
       "             'Whose fresh repair if now thou not renewest,': 1,\n",
       "             'Thou dost beguile the world, unbless some mother.': 1,\n",
       "             'For where is she so fair whose uneared womb': 1,\n",
       "             'Disdains the tillage of thy husbandry?': 1,\n",
       "             'Or who is he so fond will be the tomb,': 1,\n",
       "             'Of his self-love to stop posterity?': 1,\n",
       "             \"Thou art thy mother's glass and she in thee\": 2,\n",
       "             'Calls back the lovely April of her prime,': 2,\n",
       "             'So thou through windows of thine age shalt see,': 1,\n",
       "             'Despite of wrinkles this thy golden time.': 1,\n",
       "             'But if thou live remembered not to be,': 1,\n",
       "             'Die single and thine image dies with thee.': 1})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'a': 1, 'b': 1, 'c': 1, 'f': 2, 'd': 2})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([('a',2),('b',3),['c',2],('f',20),['d',4],('f',12),('d',11)])\n",
    "rdd1.countByKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collectAsMap\n",
    "\n",
    "```.collectAsMap()``` - return a dictionary key-value pairs for the current RDD to master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 'b', 'g': 2, 'c': 'd', 'e': 'f'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2 = sc.parallelize([(\"a\", \"b\"), (\"g\", 2), [\"c\", \"d\"], {\"e\", \"f\"}])\n",
    "rdd2.collectAsMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum\n",
    "\n",
    "Sum of elements of RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14950"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd3 = sc.parallelize(range(100, 200), 3)\n",
    "rdd3.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## isEmpty\n",
    "\n",
    "checks if the RDD is empty and return ```True``` if and only if the RDD contains no elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.isEmpty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize([]).isEmpty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize([[]]).isEmpty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some statistics methods\n",
    "\n",
    "## max\n",
    "\n",
    "Return the max value of an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd4 = sc.parallelize(range(50,150))\n",
    "rdd4.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## min\n",
    "\n",
    "Return the min value of an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd4.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mean\n",
    "\n",
    "Return the mean value of an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd4.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stdev\n",
    "\n",
    "Return the standart deviation value of an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.86607004772212"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd4.stdev()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## histogram\n",
    "\n",
    "Compute a histogram by bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([50.0, 74.75, 99.5, 124.25, 149], [25, 25, 25, 25])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd4.histogram(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stats\n",
    "\n",
    "Return a StatCounter object that captures the count, mean, stdev, max, and min of the RDDâ€™s elements in one operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count: 100, mean: 99.5, stdev: 28.86607004772212, max: 149.0, min: 50.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd4.stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "\n",
    "## map\n",
    "\n",
    "Applies a function for each element in RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Good', 'Morning'],\n",
       " ['Good', 'Evening'],\n",
       " ['Good', 'Day'],\n",
       " ['Happy', 'Birthday'],\n",
       " ['Happy', 'New', 'Year'],\n",
       " ['Nice', 'to', 'meet', 'you'],\n",
       " ['Hi'],\n",
       " ['Hello'],\n",
       " ['How', 'are', 'you?']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd5 = sc.textFile(\"sample_data/201-greetings.txt\")\n",
    "rdd5.map(lambda line: line.split()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flatMap\n",
    "\n",
    "Applies a map function for each element in RDD and flattening the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good',\n",
       " 'Morning',\n",
       " 'Good',\n",
       " 'Evening',\n",
       " 'Good',\n",
       " 'Day',\n",
       " 'Happy',\n",
       " 'Birthday',\n",
       " 'Happy',\n",
       " 'New',\n",
       " 'Year',\n",
       " 'Nice',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'you',\n",
       " 'Hi',\n",
       " 'Hello',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you?']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd5.flatMap(lambda line: line.split()).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flatMapValues\n",
    "\n",
    "Each key-value pair pass through a flatMap function and then the key-value pairs are mapped whithout changing the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 'x'), ('a', 'y'), ('a', 'z'), ('b', 'p'), ('b', 'r')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd6 = sc.parallelize([(\"a\", [\"x\", \"y\", \"z\"]), (\"b\", [\"p\", \"r\"])])\n",
    "rdd6.flatMapValues(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to select data in RDD?\n",
    "\n",
    "Methods as ```.collect``` we saw in the examples above.\n",
    "\n",
    "```.collect``` returns RDD elements as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good Morning',\n",
       " 'Good Evening',\n",
       " 'Good Day',\n",
       " 'Happy Birthday',\n",
       " 'Happy New Year',\n",
       " 'Nice to meet you',\n",
       " 'Hi',\n",
       " 'Hello',\n",
       " 'How are you?']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd5.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```.take(3)``` returns first 3 elements of a RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good Morning', 'Good Evening', 'Good Day']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd5.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```.first``` return the first element of a RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good Morning'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd5.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```.top(3)``` returns top 3 elements of a RDD sorted by descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nice to meet you', 'How are you?']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd5.top(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being sure of the last function ```.top(3)``` the sorted list is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good Day',\n",
       " 'Good Evening',\n",
       " 'Good Morning',\n",
       " 'Happy Birthday',\n",
       " 'Happy New Year',\n",
       " 'Hello',\n",
       " 'Hi',\n",
       " 'How are you?',\n",
       " 'Nice to meet you']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(rdd5.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling data\n",
    "\n",
    "```.sample()``` return a sample subset of the RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDD:  [100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119]\n",
      "Subset:  [100, 101, 103, 104, 107, 110, 113, 114, 116, 117, 118]\n"
     ]
    }
   ],
   "source": [
    "rdd7 = sc.parallelize(range(100,120))\n",
    "print(\"RDD: \", rdd7.collect())\n",
    "print(\"Subset: \", rdd7.sample(False, 0.44, 42).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```.filter()``` - filter values in the RDD, looks like a ```where``` statement of SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 102, 104, 106, 108, 110, 112, 114, 116, 118]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect even number in a range(100,150)\n",
    "rdd7.filter(lambda x: x % 2 == 0).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```.distinct``` - return a new RDD with distinct elements of the current RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good',\n",
       " 'Morning',\n",
       " 'Evening',\n",
       " 'Day',\n",
       " 'Happy',\n",
       " 'Birthday',\n",
       " 'New',\n",
       " 'Year',\n",
       " 'Nice',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'you',\n",
       " 'Hi',\n",
       " 'Hello',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you?']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd8 = rdd5.flatMap(lambda line: line.split())\n",
    "rdd8.distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```.keys()``` - return the keys in the RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'a', 'a', 'b', 'b']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rdd6 = [('a', 'x'), ('a', 'y'), ('a', 'z'), ('b', 'p'), ('b', 'r')]\n",
    "rdd9 = rdd6.flatMapValues(lambda x: x)\n",
    "rdd9.keys().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ```.keys()``` and ```.distinct()``` to return unique keys in the RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd9.keys().distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating over RDD\n",
    "\n",
    "```.foreach``` is a useful function when you desire moving your data to an external system, i.e. a database not supported by PySpark or publish to a web service. This function does not return anything. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_local_file(x):\n",
    "    with open('sample_Data/201-foreach.txt', 'a') as f:\n",
    "        f.write(str(x)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x): save_local_file(x + 1)\n",
    "rdd10 = sc.parallelize([x for x in range(100)], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd10.foreach(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
